<!DOCTYPE html>
<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
		<link rel="stylesheet" href="./css/jemdoc.css" type="text/css">
		<title>主页</title>
	</head>
	<body>
		<div class="main">
			<div class="menu">
				<div class="menu-item">
					<a class="current">Home</a>
				</div>
			</div>
			<table id="tlayout">
				<tbody>
					<tr>
						<td id="layout-content">
							<div class="toptitle">	
								</div>
							<div class="top-box">
								<div class="cell-box left-box">
									<table class="imgtable">
										<tbody>
<tr>
<td>
<p><h3>Virtual Human Group<br>Netease Fuxi AI Lab</h3><br>
We are looking for algorithm interns (PhD/master students) to work in 2022. <br>
The position requires full-time working for at least 4 months. <br>
Contact email: dingyu01@corp.netease.com<br>
</p>
</td>
											</tr>
										</tbody>
									</table>
								</div>
								<div class="cell-box right-box">
<!-- 									<div class="toptitle"> -->
										<h2>News</h2>
									<!-- </div> -->
									<table class="imgtable">
										<tbody>
											<tr>
												<td>
													<ul>
														
<li><p>[2021-11] One paper accepted to AAAI 2022.</p></li>
<li><p>[2021-09] One paper accepted to TVCG.</p></li>
<li>
<p>[2021-07] Our team is the winner of the EXPR Challenge (Basic Expression Classification) on ICCV 2021.</p>
<p>[2021-07] Our team is the winner of the AU Challenge (facial Action Unit Detection) on ICCV 2021.</p>
<p>[2021-07] Our team is the runner-up of the VA Challenge (Valence-arousal estimation) on ICCV 2021.</p>                                                                                                                                                                                                                                                 
</li>
<li><p>[2021-03] Two papers accepted to CVPR.</p></li>
<li><p>[2020-11] One paper accepted to AAAI.</p></li>
<li><p>[2020-03] One paper accepted to ICASSP.</p></li>
<li><p>[2020-03] One paper accepted to CVPR.</p></li>

													</ul>
												</td>
											</tr>
										</tbody>
									</table>
								</div>
							</div>
							<h2>Selected Publications </h2>
							<ul>
								<table class="imgtable">
									<tbody>
<tr>
<td>
<img src="./img/2022-AAAI-TalkingFace.jpeg" alt="" width="240px" height="150px">&nbsp;
</td>
<td>
<h3><font color="Purple">One-shot Talking Face Generation with Single-speaker Audio-Visual Correlation Learning</font></h3>
<p>Suzhen Wang, Lincheng Li, Yu Ding*, Xin Yu</p>
<p>AAAI Conference on Artificial Intelligence (AAAI), 2022 <br> <p>
</td>
</tr>
<tr>
<td>
<img src="./img/2021-TVCG-GuzhengAnim.jpg" alt="" width="240px" height="150px">&nbsp;
</td>
<td>
<h3><font color="Purple">A Music-driven Deep Generative Model for Guzheng Playing Animation</font></h3>
<p>Jiali Chen, Changjie Fan, Zhimeng Zhang, Gongzheng Li, Zeng Zhao, Jiajun Bu, Zhigang Deng, Yu Ding*</p>
<p>IEEE Transactions on Visualization and Computer Graphics (accepted in September 2021) <br> <p>
<div class="material"> 
[<a href="http://graphics.cs.uh.edu/wp-content/papers/2021/2021-TVCG-music-driven-guzheng-animation.pdf">pdf</a>]
[<a href="https://www.youtube.com/watch?v=-XmGKZGddxY&t=8s">video</a>]
</div>
</td>
</tr>
<tr>
<td>
<img src="./img/2021-IJCAI-TalkingFace.jpeg" alt="" width="240px" height="150px">&nbsp;
</td>
<td>
<h3><font color="Purple">Audio2Head: Audio-driven One-shot Talking-head Generation with Natural Head Motion</font></h3>
<p>Suzhen Wang, Lincheng Li, Yu Ding*, Changjie Fan, Xin Yu,</p>
<p>International Joint Conference on Artificial Intelligence (IJCAI), 2021.<br> <p>

</td>
</tr>
<tr>
<td>
<img src="./img/2021-ICCV.jpg" alt="" width="240px" height="150px">&nbsp;
</td>
<td>
<h3><font color="Purple">Prior Aided Streaming Network for Multi-task Affective Analysis</font></h3>
<p>Wei Zhang, Zunhu Guo, Keyu Chen, Lincheng Li, Zhimeng Zhang, Yu Ding, Runze Wu, Tangjie Lv, Changjie Fan</p>
<p>International Conference on Computer Vision (ICCV), 2021<p>

</td>
</tr>
<tr>
<td>
<img src="./img/2021-ICCV-ABAW2.jpeg" alt="" width="240px" height="150px">&nbsp;
</td>
<td>
<h3><font color="Purple">Prior aided streaming network for multi-task affective recognitionat the 2nd abaw2 competition</font></h3>
<p>Wei Zhang, Zunhu Guo, Keyu Chen, Lincheng Li, Zhimeng Zhang, Yu Ding*</p>
<p>ICCV-ABAW2 competitions (two winners of the EXPR and AU Challenges, the runner-up of the VA Challenge), 2021 </p>

</td>
</tr>
<tr>
<td>
<img src="./img/2021-CAWA.jpg" alt="" width="240px" height="150px">&nbsp;
</td>
<td>
<h3><font color="Purple">Learning a deep motion interpolation network for human skeleton animations</font></h3>
<p>Chi Zhou, Zhangjiong Lai, Suzhen Wang, Lincheng Li, Xiaohan Sun, Yu Ding*</p>
<p>Computer Animation and Virtual Worlds </p>

</td>
</tr>
<tr>
<td>
<img src="./img/2021-CVPR-ExpEmb.jpg" alt="" width="240px" height="150px">&nbsp;
</td>
<td>
<h3><font color="Purple">Learning a Facial Expression Embedding Disentangled From Identity</font></h3>
<p>Wei Zhang, Xianpeng Ji, Keyu Chen, Yu Ding*, Changjie Fan</p>
<p>IEEE/CVF Conference on Computer Vision and Pattern Recognition</p>
</td>
</tr>
<tr>
<td>
<img src="./img/2021-CVPR-Talking.jpg" alt="" width="240px" height="150px">&nbsp;
</td>
<td>
<h3><font color="Purple">Flow-Guided One-Shot Talking Face Generation With a High-Resolution Audio-Visual Dataset</font></h3>
<p>Zhimeng Zhang, Lincheng Li, Yu Ding*, Changjie Fan</p>
<p>IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021.</p>
</td>
</tr>
<tr>
<td>
<img src="./img/2021-AAAI-Talking.jpg" alt="" width="240px" height="150px">&nbsp;
</td>
<td>
<h3><font color="Purple">Write-a-speaker: Text-based Emotional and Rhythmic Talking-head Generation</font></h3>
<p>Lincheng Li, Suzhen Wang, Zhimeng Zhang, Yu Ding*, Yixing Zheng, Xin Yu, Changjie Fan</p>
<p>AAAI Conference on Artificial Intelligence, 2021.</p>
</td>
</tr>
<tr>
<td>
<img src="./img/2021-ICASSP-SpeechConv.jpg" alt="" width="240px" height="150px">&nbsp;
</td>
<td>
<h3><font color="Purple">One-Shot Voice Conversion Using Star-Gan</font></h3>
<p>Ruobai Wang, Yu Ding*, Lincheng Li, Changjie Fan</p>
<p>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</p>
</td>
</tr>
<tr>
<td>
<img src="./img/2020-CVPR-ExpRe.jpg" alt="" width="240px" height="150px">&nbsp;
</td>
<td>
<h3><font color="Purple">Freenet: Multi-identity face reenactment</font></h3>
<p>Jiangning Zhang, Xianfang Zeng, Mengmeng Wang, Yusu Pan, Liang Liu, Yong Liu, Yu Ding, Changjie Fan</p>
<p>IEEE/CVF Conference on Computer Vision and Pattern Recognition </p>
</td>
</tr>
<tr>
<td>
<img src="./img/2019-IVA.jpg" alt="" width="240px" height="150px">&nbsp;
</td>
<td>
<h3><font color="Purple">Text-driven Visual Prosody Generation for Embodied Conversational Agents</font></h3>
<p>Jiali Chen, Yong Liu, Zhimeng Zhang, Changjie Fan, Yu Ding*</p>
<p>ACM International Conference on Intelligent Virtual Agents </p>
</td>
</tr>
</tbody>
</table>
</ul>
</td>
</tr>
</tbody>
</table>
</div>
</body>
</html>
